\begin{abstract}
The advances in machine learning have brought about impactful improvements in perception, especially in systems that can understand images.
This thesis proposal aims to complement these improvements by studying the robustness and generalization capabilities of vision and language models.
This involves (1) identifying failure modes, i.e., situations under which these systems are prone to fail, (2) creating analysis tools and  evaluation benchmarks and metrics to help detect and diagnose these failures, and (3) developing machine learning algorithms that provide greater robustness and generalization to mitigate the risks posed by such situations.
In particular, this proposal describes five research projects -- two in image classification and three in multi-modal vision-and-language tasks that address the above goals.
AGAT is designed for making image classifiers robust to unknown shifts along pre-specified image attributes, ALT addresses the harder task of single-source domain generalization, VQA-LOL tackles logical compositions in visual question answering, ``Mutant'' is a data augmentation technique for reducing the problem of VQA dataset bias, and SDRO is a new distributed robust optimization method that uses semantic sentence transformations for improving the robustness of vision-language inference models.
Three potential research directions are discussed, (1) an empirical study of comparative effect of dataset modification on out-of-distribution accuracy and adversarial robustness, (2) a hypothesis that analyzing the interpolations between two images might point to insights about image classifier robustness, and (3) designing evaluation protocols for pre-trained V\&L models.
\end{abstract}
