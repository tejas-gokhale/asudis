\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{vqalol/images/vqa_lol_eccv.png}
    \caption{LOL model architecture showing a cross-modal feature encoder followed by our Question-Attention ($q_{\textit{\tiny ATT}}$) and Logic Attention ($\ell_{\textit{\tiny ATT}}$) modules. 
    The concatenated output of  is used by the Answering Module to predict the answer.
    % to the question (Q).
    }
    \label{fig:model}
\end{figure}