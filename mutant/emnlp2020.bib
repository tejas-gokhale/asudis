@inproceedings{gokhale2020vqa,
  title={VQA-LOL: Visual Question Answering under the Lens of Logic},
  author={Gokhale, Tejas and Banerjee, Pratyay and Baral, Chitta and Yang, Yezhou},
  booktitle={European conference on computer vision},
  year={2020},
  organization={Springer}
}

@inproceedings{goyal2017making,
  title={Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6904--6913},
  year={2017}
}

@inproceedings{lewis-etal-2019-unsupervised,
    title = "Unsupervised Question Answering by Cloze Translation",
    author = "Lewis, Patrick  and
      Denoyer, Ludovic  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1484",
    doi = "10.18653/v1/P19-1484",
    pages = "4896--4910",
    abstract = "Obtaining training data for Question Answering (QA) is time-consuming and resource-intensive, and existing QA datasets are only available for limited domains and languages. In this work, we explore to what extent high quality training data is actually required for Extractive QA, and investigate the possibility of unsupervised Extractive QA. We approach this problem by first learning to generate context, question and answer triples in an unsupervised manner, which we then use to synthesize Extractive QA training data automatically. To generate such triples, we first sample random context paragraphs from a large corpus of documents and then random noun phrases or Named Entity mentions from these paragraphs as answers. Next we convert answers in context to {``}fill-in-the-blank{''} cloze questions and finally translate them into natural questions. We propose and compare various unsupervised ways to perform cloze-to-natural question translation, including training an unsupervised NMT model using non-aligned corpora of natural questions and cloze questions as well as a rule-based approach. We find that modern QA models can learn to answer human questions surprisingly well using only synthetic training data. We demonstrate that, without using the SQuAD training data at all, our approach achieves 56.4 F1 on SQuAD v1 (64.5 F1 when the answer is a Named Entity mention), outperforming early supervised models.",
}

@inproceedings{fabbri2020template,
  title={Template-Based Question Generation from Retrieved Sentences for Improved Unsupervised Question Answering},
  author={Fabbri, Alexander R and Ng, Patrick and Wang, Zhiguo and Nallapati, Ramesh and Xiang, Bing},
  booktitle={ACL},
  year={2020}
}

@inproceedings{banerjee2020self,
  title={Self-supervised Knowledge Triplet Learning for Zero-shot Question Answering},
  author={Banerjee, Pratyay and Baral, Chitta},
  booktitle={EMNLP},
  year={2020}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@inproceedings{tan2019lxmert,
  title={LXMERT: Learning Cross-Modality Encoder Representations from Transformers},
  author={Tan, Hao and Bansal, Mohit},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={5103--5114},
  year={2019}
}


@inproceedings{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={NAACL-HLT (1)},
  year={2019}
}
@inproceedings{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  booktitle={Advances in neural information processing systems},
  pages={91--99},
  year={2015}
}

@inproceedings{suhr2019corpus,
  title={A Corpus for Reasoning About Natural Language Grounded in Photographs},
  author={Suhr, Alane and Zhou, Stephanie and Zhang, Ally and Zhang, Iris and Bai, Huajun and Artzi, Yoav},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}

@inproceedings{yu2018generative,
  title={Generative image inpainting with contextual attention},
  author={Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5505--5514},
  year={2018}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{bajcsy2018revisiting,
  title={Revisiting active perception},
  author={Bajcsy, Ruzena and Aloimonos, Yiannis and Tsotsos, John K},
  journal={Autonomous Robots},
  volume={42},
  number={2},
  pages={177--196},
  year={2018},
  publisher={Springer}
}

@inproceedings{marino2019ok,
  title={Ok-vqa: A visual question answering benchmark requiring external knowledge},
  author={Marino, Kenneth and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3195--3204},
  year={2019}
}

@inproceedings{das2017visual,
  title={Visual dialog},
  author={Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Moura, Jos{\'e} MF and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={326--335},
  year={2017}
}

@inproceedings{hudson2019gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6700--6709},
  year={2019}
}


@inproceedings{kaushik2018much,
  title={How Much Reading Does Reading Comprehension Require? A Critical Investigation of Popular Benchmarks},
  author={Kaushik, Divyansh and Lipton, Zachary C},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={5010--5015},
  year={2018}
}


@InProceedings{vqa-cp,
author = {Aishwarya Agrawal and Dhruv Batra and Devi Parikh and Aniruddha Kembhavi},
title = {Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2018},
}

@inproceedings{selvaraju2020squinting,
    title={SQuINTing at VQA Models: Interrogating VQA Models with Sub-Questions},
    author={Ramprasaath R. Selvaraju and Purva Tendulkar and Devi Parikh and Eric Horvitz and Marco Ribeiro and Besmira Nushi and Ece Kamar},
    year={2020},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}
}

@inproceedings{clark2019don,
  title={Donâ€™t Take the Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases},
  author={Clark, Christopher and Yatskar, Mark and Zettlemoyer, Luke},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={4060--4073},
  year={2019}
}

@inproceedings{ramakrishnan2018overcoming,
  title={Overcoming language priors in visual question answering with adversarial regularization},
  author={Ramakrishnan, Sainandan and Agrawal, Aishwarya and Lee, Stefan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1541--1551},
  year={2018}
}

@inproceedings{poliak2018hypothesis,
  title={Hypothesis Only Baselines in Natural Language Inference},
  author={Poliak, Adam and Naradowsky, Jason and Haldar, Aparajita and Rudinger, Rachel and Van Durme, Benjamin},
  booktitle={Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics},
  pages={180--191},
  year={2018}
}

@inproceedings{mccoy2019right,
  title={Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference},
  author={McCoy, Tom and Pavlick, Ellie and Linzen, Tal},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={3428--3448},
  year={2019}
}

@inproceedings{chen2020counterfactual,
  title={Counterfactual samples synthesizing for robust visual question answering},
  author={Chen, Long and Yan, Xin and Xiao, Jun and Zhang, Hanwang and Pu, Shiliang and Zhuang, Yueting},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10800--10809},
  year={2020}
}

@inproceedings{gutmann2010noise,
  title={Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author={Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle={Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages={297--304},
  year={2010}
}
@incollection{RUBI,
title = {RUBi: Reducing Unimodal Biases for Visual Question Answering},
author = {Cadene, Remi and Dancette, Corentin and Ben younes, Hedi and Cord, Matthieu and Parikh, Devi},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {841--852},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8371-rubi-reducing-unimodal-biases-for-visual-question-answering.pdf}
}

@article{willing2011shifting,
  title={Shifting the balance: antibiotic effects on host--microbiota mutualism},
  author={Willing, Benjamin P and Russell, Shannon L and Finlay, B Brett},
  journal={Nature Reviews Microbiology},
  volume={9},
  number={4},
  pages={233--243},
  year={2011},
  publisher={Nature Publishing Group}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@inproceedings{shah2019cycle,
  title={Cycle-consistency for robust visual question answering},
  author={Shah, Meet and Chen, Xinlei and Rohrbach, Marcus and Parikh, Devi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6649--6658},
  year={2019}
}

@inproceedings{asai2020logic,
  title={Logic-Guided Data Augmentation and Regularization for Consistent Question Answering},
  author={Asai, Akari and Hajishirzi, Hannaneh},
  booktitle={ACL},
  year={2020}
}

@inproceedings{agarwal2020towards,
  title={Towards causal vqa: Revealing and reducing spurious correlations by invariant and covariant semantic editing},
  author={Agarwal, Vedika and Shetty, Rakshith and Fritz, Mario},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9690--9698},
  year={2020}
}

@inproceedings{ray2019sunny,
  title={Sunny and Dark Outside?! Improving Answer Consistency in VQA through Entailed Question Generation},
  author={Ray, Arijit and Sikka, Karan and Divakaran, Ajay and Lee, Stefan and Burachas, Giedrius},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={5863--5868},
  year={2019}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}

@article{teney2020unshuffling,
  title={Unshuffling Data for Improved Generalization},
  author={Teney, Damien and Abbasnejad, Ehsan and Hengel, Anton van den},
  journal={arXiv preprint arXiv:2002.11894},
  year={2020}
}

@inproceedings{agrawal2018don,
	title={Don't just assume; look and answer: Overcoming priors for visual question answering},
	author={Agrawal, Aishwarya and Batra, Dhruv and Parikh, Devi and Kembhavi, Aniruddha},
	booktitle={CVPR},
	year={2018}
}

@inproceedings{cadene2019murel,
	title={Murel: Multimodal relational reasoning for visual question answering},
	author={Cadene, Remi and Ben-Younes, Hedi and Cord, Matthieu and Thome, Nicolas},
	booktitle={CVPR},
	year={2019}
}

@inproceedings{cadene2019rubi,
	title={RUBi: Reducing Unimodal Biases in Visual Question Answering},
	author={Cadene, Remi and Dancette, Corentin and Ben-younes, Hedi and Cord, Matthieu and Parikh, Devi},
	booktitle={NeurIPS},
	year={2019}
}

@inproceedings{hudson2019learning,
	title={Learning by abstraction: The neural state machine},
	author={Hudson, Drew A and Manning, Christopher D},
	booktitle={NeurIPS},
	year={2019}
}

@inproceedings{wu2019self,
	title={Self-Critical Reasoning for Robust Visual Question Answering},
	author={Wu, Jialin and Mooney, Raymond J},
	booktitle={NeurIPS},
	year={2019}
}
@inproceedings{malinowski2018learning,
	title={Learning visual question answering by bootstrapping hard attention},
	author={Malinowski, Mateusz and Doersch, Carl and Santoro, Adam and Battaglia, Peter},
	booktitle={ECCV},
	year={2018}
}

@inproceedings{hu2018learning,
  title={Learning answer embeddings for visual question answering},
  author={Hu, Hexiang and Chao, Wei-Lun and Sha, Fei},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5428--5436},
  year={2018}
}

@article{teney2016zero,
  title={Zero-shot visual question answering},
  author={Teney, Damien and Hengel, Anton van den},
  journal={arXiv preprint arXiv:1611.05546},
  year={2016}
}

@book{mitchell1980need,
  title={The need for biases in learning generalizations},
  author={Mitchell, Tom M},
  year={1980},
  publisher={Department of Computer Science, Laboratory for Computer Science Research~â€¦}
}

@inproceedings{bigham2010vizwiz,
  title={VizWiz: nearly real-time answers to visual questions},
  author={Bigham, Jeffrey P and Jayant, Chandrika and Ji, Hanjie and Little, Greg and Miller, Andrew and Miller, Robert C and Miller, Robin and Tatarowicz, Aubrey and White, Brandyn and White, Samual and others},
  booktitle={Proceedings of the 23nd annual ACM symposium on User interface software and technology},
  pages={333--342},
  year={2010}
}

@article{suhr2018corpus,
  title={A corpus for reasoning about natural language grounded in photographs},
  author={Suhr, Alane and Zhou, Stephanie and Zhang, Ally and Zhang, Iris and Bai, Huajun and Artzi, Yoav},
  journal={arXiv preprint arXiv:1811.00491},
  year={2018}
}

@inproceedings{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13--23},
  year={2019}
}

@inproceedings{su2019vl,
  title={VL-BERT: Pre-training of Generic Visual-Linguistic Representations},
  author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{li2020unicoder,
  title={Unicoder-VL: A Universal Encoder for Vision and Language by Cross-Modal Pre-Training.},
  author={Li, Gen and Duan, Nan and Fang, Yuejian and Gong, Ming and Jiang, Daxin and Zhou, Ming},
  booktitle={AAAI},
  pages={11336--11344},
  year={2020}
}

@inproceedings{chen2019uniter,
  title={Uniter: Learning universal image-text representations},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and Kholy, Ahmed El and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European Conference on Computer Vision},
  year={2019}
}

@article{honnibal2017spacy,
  title={spacy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing},
  author={Honnibal, Matthew and Montani, Ines},
  journal={To appear},
  volume={7},
  number={1},
  year={2017}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{lloyd1982least,
  title={Least squares quantization in PCM},
  author={Lloyd, Stuart},
  journal={IEEE transactions on information theory},
  volume={28},
  number={2},
  pages={129--137},
  year={1982},
  publisher={IEEE}
}

@inproceedings{teney2020learning,
  title={Learning what makes a difference from counterfactual examples and gradient supervision},
  author={Teney, Damien and Abbasnedjad, Ehsan and Hengel, Anton van den},
  booktitle={European conference on computer vision},
  year={2020},
  organization={Springer}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

@inproceedings{hendrycks2019augmix,
  title={AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty},
  author={Hendrycks, Dan and Mu, Norman and Cubuk, Ekin Dogus and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{
madry2018towards,
title={Towards Deep Learning Models Resistant to Adversarial Attacks},
author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=rJzIBfZAb},
}

@article{kervadec2020roses,
  title={Roses Are Red, Violets Are Blue... but Should Vqa Expect Them To?},
  author={Kervadec, Corentin and Antipov, Grigory and Baccouche, Moez and Wolf, Christian},
  journal={arXiv preprint arXiv:2006.05121},
  year={2020}
}

@misc{lemminflect,
      title  = "LemmInflect. A python module for English word lemmatization and inflection.",
      author={Brad Jascob},
      note    = {\url{https://github.com/bjascob/LemmInflect}},
      year   = "v0.2.1 (February 22, 2020)"
    }

@inproceedings{kafle2016answer,
  title={Answer-type prediction for visual question answering},
  author={Kafle, Kushal and Kanan, Christopher},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4976--4984},
  year={2016}
}
